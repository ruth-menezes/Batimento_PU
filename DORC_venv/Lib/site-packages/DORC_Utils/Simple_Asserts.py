from prefect import task
import pandas as pd
import collections
import six
import numpy
from datetime import datetime, timedelta


pd.set_option('mode.chained_assignment', None)


def iterable(arg):
    if isinstance(arg, collections.Iterable) and not isinstance(arg, six.string_types):
        return list(arg)
    return [arg]


def normalize(kwargs):
    lens = []
    for k, v in kwargs.items():
        kwargs[k] = iterable(v)
        lens += [len(kwargs[k])]
    lcm = numpy.lcm.reduce(lens)
    for k, v in kwargs.items():
        kwargs[k] = v*int(lcm/len(v))
    return kwargs, int(lcm)


def get_ok_assert(data_df, validations):
    comments = pd.DataFrame()
    for column in [x[2:] for x in data_df.columns if "__" == x[:2]]:
        comments[column] = data_df.loc[:, '__' + column]
        validations['Comments'] = comments.to_dict(orient='records')
        validations['Status'] = 'OK'
    return validations


def get_comments(data_df, first_only=False):
    comments = pd.DataFrame()
    for column in [x[2:] for x in data_df.columns if "__" == x[:2]]:
        if first_only:
            comments[column] = data_df.loc[:, '__' + column].head(1)
        else:
            comments[column] = data_df.loc[:, '__' + column]
    return comments


def get_assert_return(data_df, validation, return_ok, return_type):
    if return_ok and validation.empty:
        if return_type == 'bool':
            return True
        elif return_type == 'dataframe':
            return get_ok_assert(data_df, validation)
        return True, get_ok_assert(data_df, validation)
    if validation.empty:
        if return_type == 'bool':
            return True
        elif return_type == 'tuple':
            return True, validation
    if return_type == 'bool':
        return False
    elif return_type == 'tuple':
        return False, validation
    return validation


@task
def assert_column_order(reference_df, data_df, return_ok=True, return_type='DataFrame'):
    """
    Compares the columns of 2 different data_dfs, to discover if there is a missing or new column.

    Args:
        reference_df (pandas.DataFrame): Dataframe with the expected columns.
        data_df (pandas.DataFrame): Dataframe to be validated.
        return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                       description of each row with status OK. If return_ok is False the dataframe will
                                       be empty.
        return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                          if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                          if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

    Returns:
        pandas.Dataframe: Table with two columns and up to 1 row.


        If empty or the Status column is 'Ok' the data dataframe columns are the same to the reference dataframe columns.
        The Status column is either 'Ok' or 'Alert' depending on the whether the columns are as expected.
        The comments column is a dictionary with information about the Table and the columns diferences

        pandas.DataFrame
        A DataFrame comprising all inconsistencies found, listing the column name and its corresponding assert result.
        Possible validation values are: "New column", "Missing column" and "Wrong order (expected X got Y)".

    Example:
        >>> from prefect import task
        >>> from DORC_Utils import BBM_Flow, read_publicador, assert_column_order
        >>>
        >>>
        >>> with BBM_Flow("My flow") as flow:
        >>>     ref_data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         data_base='20191002',
        >>>         parameter_columns=False
        >>>     )
        >>>     data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         data_base='20200102',
        >>>         parameter_columns=False
        >>>     )
        >>>     results = assert_column_order(
        >>>         reference_df=ref_data_df,
        >>>         data_df=data_df
        >>>     )
        >>>
        >>> if __name__ == "__main__":
        >>>     flow.run()
    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')
    if not isinstance(reference_df, pd.DataFrame):
        raise TypeError(f"reference_df should be a DataFrame and not {type(reference_df)}")
    if reference_df.columns.empty:
        raise Exception(f"reference_df must have columns can not be empty")
    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")

    reference_columns = pd.DataFrame(reference_df.columns, columns=['column_name'])
    reference_columns['ref_order'] = reference_columns.index + 1
    data_columns = pd.DataFrame(data_df.columns, columns=['column_name'])
    data_columns['data_order'] = data_columns.index + 1
    merge_columns = reference_columns.merge(data_columns, how='outer', indicator='status')

    order_match = merge_columns['ref_order'] == merge_columns['data_order']
    both_present = merge_columns['status'] == 'both'

    merge_columns['status'] = merge_columns['status'].replace(
        {'left_only': 'Missing column', 'right_only': 'New column'})
    merge_columns['status'] = merge_columns.apply(
        lambda row: 'Wrong order (expected %d got %d)' % (
            row["ref_order"], row["data_order"]) if row['status'] == 'both' else row['status'],
        axis=1)

    merge_columns = merge_columns.loc[~order_match | ~both_present]
    merge_columns = merge_columns[['column_name', 'status']]

    validations = pd.DataFrame(columns=['Status', 'Comments'])
    if not merge_columns.empty:
        validation = pd.DataFrame({'Status': ['Alert']})
        comments = get_comments(data_df, True).to_dict(orient='records')
        comments[0]['wrong columns'] = merge_columns.set_index('column_name').squeeze().to_dict()

        validation['Comments'] = comments
        validations = validations.append(validation)
    return get_assert_return(data_df, validations, return_ok, return_type)


@task
def assert_column_interval(data_df, columns, min_value=None, max_value=None, min_value_warning=None,
                           max_value_warning=None, return_ok=True, return_type='DataFrame'):
    """
    Assert whether the column values ​​are within a given range.

    Args:
        data_df(DataFrame): Published data
        columns(String): columns to be validated.
                            String for just one column.
                            String list for more columns.
        min_value(int): Minimum tolerable value for Danger status.
                           Int for just one minimum limit.
                           Int List for more than one  minimum limit.
        max_value(int): Maximum tolerable value for Alert status
                           Int for just one maximum limit.
                           Int List for more than one  maximum limit.
        min_value_alert(int, optional): Minimum tolerable value for Alert status. Defaults to None.
                                          Int for just one minimum limit.
                                          Int List for more than one  minimum limit.
                                          Empty for no Alert Status
        max_value_alert(int, optional): Maximum tolerable value for Alert status. Defaults to None.
                                                  Int for just one maximum limit.
                                                  Int List for more than one maximum limit.
                                                  Empty for no Alert Status
        return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                       description of each row with status OK. If return_ok is False the dataframe will
                                       be empty.
        return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                          if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                          if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

    Returns:
        pandas.DataFrame: Table with two columns and n rows.


        If empty all columns satisfy all possible range values.
        The number of lines will be the values ​​of each column that are not in at least one possible range.
        For each value outside some range, it will be in the output table.
        The Status column is the status output for each value in a given range.
        The comments column is a dictionary with information about the line and the range
        in which it did not pass validation.

    Examples:
        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=1000.0, min_value=100.0)
            assert for (100.0 < "QTDE Fech" < 1000.0)
            Alert Status only

        >>> assert_column_interval(pandas.DataFrame, columns=["QTDE Fech", "QTDE Imp"], max_value=1000.0, min_value=100.0)
            assert for (100.0 < "QTDE Fech" < 1000.0) and (100.0 < "QTDE Imp" < 1000.0)
            Alert Status only

        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=1000.0, min_value=100.0, min_value_alert=300.0, max_value_alert=800.0)
            assert for (100.0 < "QTDE Fech" < 1000.0) and (300.0 < "QTDE Fech" < 800.0)
            Alert and Warning Status

        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=[1000.0, 900.0], min_value=[100.0, 90.0])
            assert for (100.0 < "QTDE Fech" < 1000.0) and (90.0 < "QTDE Fech" < 1000.0) and (100.0 < "QTDE Fech" < 900.0) and (90.0 < "QTDE Fech" < 900.0)
            Alert Status only

        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=1000.0, min_value=100.0, return_type='Bool')
             assert for (100.0 < "QTDE Fech" < 1000.0)
             return: If 100.0 < "QTDE Fech" < 1000.0, True
                     If 100.0 > "QTDE Fech" or "QTDE Fech" > 1000.0, False

        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=1000.0, min_value=100.0, return_type='DataFrame', return_ok=True)
             assert for (100.0 < "QTDE Fech" < 1000.0)
             return: If 100.0 > "QTDE Fech"  or "QTDE Fech" > 1000.0,  DataFrame with Alert Status
                     If 100.0 < "QTDE Fech" < 1000.0, DataFrame with Ok Status.

        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=1000.0, min_value=100.0, return_type='Tuple')
             assert for (100.0 < "QTDE Fech" < 1000.0)
             return: (Bool, DataFrame)

        >>> assert_column_interval(pandas.DataFrame, columns="QTDE Fech", max_value=1000.0, min_value=100.0, return_ok=False)
             assert for (100.0 < "QTDE Fech" < 1000.0)
             return: If 100.0 > "QTDE Fech"  or "QTDE Fech" > 1000.0,  DataFrame with Alert Status
                     If 100.0 < "QTDE Fech" < 1000.0, empty DataFrame

        >>> from prefect import task
        >>> from DORC_Utils import BBM_Flow, read_publicador, assert_column_interval
        >>>
        >>> with BBM_Flow("My flow") as flow:
        >>>     data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         dataref_inicio='20201002',
        >>>         dataref_fim='20201002'
        >>>     )
        >>>     results = assert_column_interval(
        >>>         data_df,
        >>>         columns='Actual Rate',
        >>>         min_value=5,
        >>>         max_value=6
        >>>     )
        >>>
        >>> if __name__ == "__main__":
        >>>     flow.run()
    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')
    if (type(columns) != list and type(columns) != str) or (type(columns) == list and type(columns[0] != str)):
        raise TypeError(f"columns should be a String or String List not {type(columns)}")

    max_value = float(max_value) if max_value else None
    max_value_alert = float(max_value_warning) if max_value_warning else None
    min_value = float(min_value) if min_value else None
    min_value_alert = float(min_value_warning) if min_value_warning else None

    if max_value is None and min_value is None:
        raise Exception("at least one of min_value and max_value needs to be initialized")

    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")

    kwargs_dict = {
        'Column': columns,
        'Min_Value': min_value,
        'Max_Value': max_value,
        'Min_Value_Alert': min_value_alert,
        'Max_Value_Alert': max_value_alert
    }
    kwargs_dict, lcm = normalize(kwargs_dict)
    validations = pd.DataFrame(columns=['Status', 'Comments'])
    for i in range(lcm):
        kwargs_i = {}
        for k, _ in kwargs_dict.items():
            kwargs_i[k] = kwargs_dict[k][i]
        small_alert = pd.DataFrame()
        big_alert = pd.DataFrame()

        if kwargs_i['Min_Value_Alert'] and kwargs_i['Min_Value_Alert'] > kwargs_i['Min_Value']:
            small_alert = data_df[(data_df[kwargs_i['Column']] < kwargs_i['Min_Value_Alert'])
                                  & (data_df[kwargs_i['Column']] >= kwargs_i['Min_Value'])]
        if kwargs_i['Max_Value_Alert'] and kwargs_i['Max_Value_Alert'] < kwargs_i['Max_Value']:
            big_alert = data_df[(data_df[kwargs_i['Column']] > kwargs_i['Max_Value_Alert'])
                                & (data_df[kwargs_i['Column']] <= kwargs_i['Max_Value'])]

        small_danger = data_df[data_df[kwargs_i['Column']] < kwargs_i['Min_Value']]
        big_danger = data_df[data_df[kwargs_i['Column']] > kwargs_i['Max_Value']]
        if kwargs_i['Min_Value_Alert'] and kwargs_i['Max_Value_Alert']:
            small_alert['Status'] = 'Warning'
            big_alert['Status'] = 'Warning'
        small_danger['Status'] = 'Alert'
        big_danger['Status'] = 'Alert'

        if kwargs_i['Min_Value_Alert'] and kwargs_i['Max_Value_Alert']:
            validations_i = pd.concat([small_alert, big_alert, small_danger, big_danger])
        else:
            validations_i = pd.concat([small_danger, big_danger])
        comments = get_comments(validations_i)
        comments['Min_Value_Warning'] = kwargs_i['Min_Value_Alert']
        comments['Min_Value_Alert'] = kwargs_i['Min_Value']
        comments['Max_Value_Warning'] = kwargs_i['Max_Value_Alert']
        comments['Max_Value_Alert'] = kwargs_i['Max_Value']
        comments['Value'] = validations_i[kwargs_i['Column']]
        comments['Column'] = kwargs_i['Column']

        validations_i['Comments'] = comments.to_dict(orient='records')
        validations = validations.append(validations_i[['Status', 'Comments']])
    return get_assert_return(data_df, validations, return_ok, return_type)


def _get_type(type_map, type):
    for key in type_map:
        if type in type_map.get(key):
            return key
    return


@task
def assert_data_type(data_df, columns, column_type, return_ok=True, return_type='DataFrame'):
    """
    Assert whether the values ​​of one or more columns belong to a given type.

    Args:
        data_df(DataFrame): Published data
        columns(String or List(String)): columns to be validated.
                            String for just one column.
                            String list for more columns.
        column_type(String or List(String)):  String Type(Number, Text, Date, Bool)
                                 String for just one type.
                                 String List for more than one type.
        return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                       description of each row with status OK. If return_ok is False the dataframe will
                                       be empty.
        return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                          if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                          if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

    Returns:
        pandas.Dataframe: Table with two columns and n rows.


        If empty all columns satisfy all possible types.
        The number of rows will be the number of columns that do not satisfy a possible type.
        The Status column is the status output for each column type compared with a given type.
        The comments column is a dictionary with information about the column and the type
        which it did not pass validation.

    Examples:
        >>> run_data_type(pandas.DataFrame, columns='Column_A', column_type='Date', return_ok=True, return_type='DataFrame')
            assert if column column "Column_A" is of type "Date"
            return: If "Column_A" is of type "Date": DataFrame with Ok Status
                    If "Column_A" is not of type "Date": DataFrame with Alert Status

        >>> run_data_type(pandas.DataFrame, columns='Column_A', column_type='Date', return_ok=False, return_type='DataFrame')
            assert if column column "Data Atual" is of type "Date"
            return: If "Column_A" is of type "Date": Empty DataFrame
                    If "Column_A" is not of type "Date": DataFrame with Alert Status

        >>> run_data_type(pandas.DataFrame, columns='Column_A', column_type='Date', return_type='Bool')
            assert if column column "Data Atual" is of type "Date"
            return: If "Column_A" is of type "Date": True
                    If "Column_A" is not of type "Date": False

        >>> run_data_type(pandas.DataFrame, columns='Column_A', column_type='Date', return_ok=False, return_type='Tuple')
            assert if column column "Data Atual" is of type "Date"
            return: If "Column_A" is of type "Date": (True, Empty DataFrame)
                    If "Column_A" is not of type "Date": (False, DataFrame with Alert Status)

        >>> run_data_type(pandas.DataFrame, columns='Column_A', column_type=['Number', 'Date'])
            assert if column "Column_A" is of type "Number" and if column "Column_A" is of type "Date"

        >>> run_data_type(pandas.DataFrame, columns=['Column_A', 'Column_B'], column_type='Number')
            assert if column "Column_A" is of type "Number" and if "Column_B" is of type "Date"

        >>> from prefect import task
        >>> from DORC_Utils import BBM_Flow, read_publicador, assert_data_type
        >>>
        >>> with BBM_Flow("My flow") as flow:
        >>>     data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         dataref_inicio='20201002',
        >>>         dataref_fim='20201002'
        >>>     )
        >>>     results = assert_data_type(
        >>>         data_df,
        >>>         columns=['Actual Rate', 'CCY buy'],
        >>>         column_type=['Number', 'Text']
        >>>     )
        >>>
        >>> if __name__ == "__main__":
        >>>     flow.run()

    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')
    if (type(columns) != list and type(columns) != str) or (type(columns) == list and type(columns[0]) != str):
        raise TypeError(f"columns should be a String or String List not {type(columns)}")
    if (type(column_type) != list and type(column_type) != str) or (type(column_type) == list and type(column_type[0]) != str):
        raise TypeError(f"column_type should be a String or String List not {type(columns)}")
    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")
    type_map = {
        'Number': [numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32,
                   numpy.uint64, numpy.intp, numpy.uintp, numpy.float32, numpy.float64, numpy.complex64,
                   numpy.complex128],
        'Text': [numpy.object],
        'Date': [numpy.datetime64, numpy.dtype('datetime64[ns]')],
        'Bool': [numpy.bool_]
    }
    kwargs_dict = {
        'Column': columns,
        'Column_Type': column_type
    }
    kwargs_dict, lcm = normalize(kwargs_dict)
    validations = pd.DataFrame(columns=['Status', 'Comments'])
    for i in range(lcm):
        kwargs_i = {}
        for k, _ in kwargs_dict.items():
            kwargs_i[k] = kwargs_dict[k][i]

        if data_df[kwargs_i['Column']].infer_objects().dtype not in type_map[kwargs_i['Column_Type']]:
            if data_df[kwargs_i['Column']].infer_objects().dtype == numpy.object and kwargs_i['Column_Type'] == 'Date':
                try:
                    pd.to_datetime(data_df[kwargs_i['Column']])
                    continue
                except:
                    pass
            validations_i = pd.DataFrame({'Status': ['Alert']})
            comments = get_comments(data_df, True)
            comments['Expected_Column_Type'] = kwargs_i['Column_Type']
            comments['Column_Type'] = _get_type(type_map, data_df[kwargs_i['Column']].infer_objects().dtype)
            comments['Column'] = kwargs_i['Column']
            validations_i['Comments'] = comments.to_dict(orient='records')
            validations = validations.append(validations_i[['Status', 'Comments']])
    return get_assert_return(data_df, validations, return_ok, return_type)


@task
def assert_number_of_lines(reference_df, data_df, variation_alert, variation_warning=None, return_ok=True,
                           return_type='DataFrame'):
    """
    Assert whether data_df has an unusual number of rows given a limit variation and a reference table

    Args:
        data_df(DataFrame): Published table.
        reference_data(DataFrame): Another published table to be used as a reference for validation.
                                    The variation of data_df lines will be measured in relation to reference_data.
        variation_alert(float): Tolerable percentage change for Alert status.
        variation_warning(float, optional): Tolerable percentage change for Warning status. Defaults to None.
        return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                       description of each row with status OK. If return_ok is False the dataframe will
                                       be empty.
        return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                          if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                          if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

    Returns:
        pandas.Dataframe: Table with two columns and up to 2 rows.


        If empty all columns satisfy all percentage change.
        The Status column is the status output for each value in a given range.
        The comments column is a dictionary with information about the Table
        and the percentage change measured in relation to reference_data.

    Examples:
        >>> assert_number_of_lines(reference_df, data_df, variation_alert=80, return_ok=True, return_type='DataFrame')
            assert if (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80
            return: If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80: DataFrame with Ok Status
                    If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 <= 80: DataFrame with Alert Status

        >>> assert_number_of_lines(reference_df, data_df, variation_alert=80, return_ok=False, return_type='DataFrame')
            assert if (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80
            return: If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80: Empty DataFrame
                    If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 <= 80: DataFrame with Alert Status

        >>> assert_number_of_lines(reference_df, data_df, variation_alert=80, return_type='Bool')
            assert if (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80
            return: If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80: True
                    If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 <= 80: False

        >>> assert_number_of_lines(reference_df, data_df, variation_alert=80, return_ok=False, return_type='Tuple')
            assert if (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80
            return: If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80: (True, Empty DataFrame)
                    If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 <= 80: (False, DataFrame with Alert Status)

        >>> assert_number_of_lines(reference_df, data_df, variation_warning=80, variation_alert=50)
            assert if (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 80 and
            if (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 > 50
            return: If 50 < (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) * 100 < 80 : DataFrame with Warning Satus
                    If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df)) < 50: DataFrame with Alert Status
                    If (1 - abs(number_of_rows_data_df / number_of_rows_reference_df))  > 80: DataFrame with Ok Status

        >>> from prefect import task
        >>> from DORC_Utils import BBM_Flow, read_publicador, assert_number_of_lines
        >>>
        >>> with BBM_Flow("My flow") as flow:
        >>>     ref_data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         dataref_inicio='20191002',
        >>>         dataref_fim='20191002'
        >>>     )
        >>>     data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         dataref_inicio='20200102',
        >>>         dataref_fim='20200102'
        >>>     )
        >>>     results = assert_number_of_lines(
        >>>         ref_data_df,
        >>>         data_df,
        >>>         variation_danger=10
        >>>     )
        >>>
        >>> if __name__ == "__main__":
        >>>     flow.run()
    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')
    if not isinstance(reference_df, pd.DataFrame):
        raise TypeError(f"reference_df should be a DataFrame and not {type(reference_df)}")
    if reference_df.empty:
        raise Exception(f"reference_df can not be empty")
    if (type(variation_alert) != float and type(variation_alert) != int) or \
            (variation_warning is not None and (type(variation_warning) != float and type(variation_warning) != int)):
        raise TypeError(f"variation_danger and variation_alert should be float or int and not "
                        f"{type(variation_alert)} and {type(variation_warning)}")
    if variation_alert <= 0 or (variation_warning is not None and variation_warning <= 0):
        raise Exception("variation_danger and variation_Alert should be greater than 0")
    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")
    len_data = len(data_df)
    len_reference = len(reference_df)
    variation = (1 - len_data/len_reference) * 100
    validations = pd.DataFrame(columns=['Status', 'Comments'])
    if abs(variation) > variation_alert:
        validation = pd.DataFrame({'Status': ['Alert']})
        comments = get_comments(data_df, True)
        comments['Danger_Variation'] = f"{variation_alert}%"
        comments['Actual_Variation'] = f"{variation}%"
        comments['Number_of_rows_data_df'] = len_data
        comments['Number_of_rows_reference_df'] = len_reference
        validation['Comments'] = comments.to_dict(orient='records')
        validations = validations.append(validation)
    elif variation_warning and abs(variation) > variation_warning:
        validation = pd.DataFrame({'Status': ['Warning']})
        comments = get_comments(data_df, True)
        comments['Alert_Variation'] = f"{variation_warning}%"
        comments['Danger_Variation'] = f"{variation_alert}%"
        comments['Actual_Variation'] = f"{variation}%"
        validation['Comments'] = comments.to_dict(orient='records')
        validations = validations.append(validation)
    return get_assert_return(data_df, validations, return_ok, return_type)


@task
def assert_duplicated_values(data_df, subset=None, return_ok=True, return_type='DataFrame'):
    """
    Assert whether a column or a subset of columns has duplicate rows.

    Args:
        data_df(DataFrame): Published table.
        subset:(String, optional): Subset of columns to look for duplicate rows. Default None.
                                           String for just one column.
                                           String list for more columns.
                                           If None all columns will be considered.
        return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                       description of each row with status OK. If return_ok is False the dataframe will
                                       be empty.
        return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                          if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                          if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

    Returns:
        pandas.Dataframe: Table with two columns and up to 1 rows.


        If empty there is no duplicated rows..
        The comments column is a dictionary with information about the Table
        and list of duplicate row indexes.

    Examples:
        >>> assert_duplicated_values(data_df, subset = "Column_A", return_ok=True, return_type='DataFrame')
            assert whether there are duplicated values in "Column_A"
            return: If there are duplicated values in "Column_A": DataFrame with Alert Status
                    If there are not duplicated values in "Column_A": DataFrame with Ok Status

        >>> assert_duplicated_values(data_df, subset = "Column_A", return_ok=False, return_type='DataFrame')
            assert whether there are duplicated values in "Column_A"
            return: If there are duplicated values in "Column_A": DataFrame with Alert Status
                    If there are not duplicated values in "Column_A": Empty DataFrame

        >>> assert_duplicated_values(data_df, subset = "Column_A", return_type='Bool')
            assert whether there are duplicated values in "Column_A"
            return: If there are duplicated values in "Column_A": False
                    If there are not duplicated values in "Column_A": True

        >>> assert_duplicated_values(data_df, subset = "Column_A", return_ok=False, return_type='Tuple')
            assert whether there are duplicated values in "Column_A"
            return: If there are duplicated values in "Column_A": (False, DataFrame with Alert Status)
                    If there are not duplicated values in "Column_A": (True, Empty DataFrame)

        >>> assert_duplicated_values(pandas.Dataframe, subset = ['Column_A','Column_B', 'Column_C'])
            assert whether there are duplicated rows in columns 'Column_A','Column_B', 'Column_C'
            return: If there are duplicated rows in 'Column_A','Column_B', 'Column_C': DataFrame with Alert Status
                    If there are not duplicated rows in 'Column_A','Column_B', 'Column_C': DataFrame with Ok Status

        >>> from prefect import task
        >>> from DORC_Utils import BBM_Flow, read_publicador, assert_duplicated_values
        >>>
        >>> with BBM_Flow("My flow") as flow:
        >>>     data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         dataref_inicio='20200102',
        >>>         dataref_fim='20200102'
        >>>     )
        >>>     results = assert_duplicated_values(
        >>>         data_df
        >>>     )
        >>>
        >>> if __name__ == "__main__":
        >>>     flow.run()

    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')
    if subset is not None and (type(subset) == list and type(subset[0]) != str):
        raise TypeError(f"subset should be a String or String List not {type(subset)}")
    if subset is not None and (type(subset) != list and type(subset[0]) != str):
        raise TypeError(f"subset should be a String or String List not {type(subset)}")
    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")
    subset = subset or data_df.columns
    result_false = data_df.duplicated(subset=subset, keep=False)
    result_first = data_df.duplicated(subset=subset, keep='first')
    result_df = data_df[(~result_first) & (result_false)]
    validations = pd.DataFrame(columns=['Status', 'Comments'])
    if not result_df.empty:
        data_df['__Column_Values'] = data_df[subset].to_dict(orient='records')
        comments = get_comments(data_df, True)
        comments['Columns'] = [subset]
        validations = pd.DataFrame()
        validations['Comments'] = comments.to_dict(orient='records')
        validations['Status'] = 'Alert'
    return get_assert_return(data_df, validations, return_ok, return_type)


def _find_gap_wd(dates, reference_date, end_date):
    dates = list(set(dates))
    gaps = []
    while reference_date <= end_date:
        if reference_date not in dates and reference_date.weekday() < 5:
            gaps.append(reference_date)
        reference_date += timedelta(days=1)
    return gaps


@task
def assert_daily_reports(data_df, column=None, start_date=None, end_date=None, return_ok=True, return_type='DataFrame'):
    """
    Assert whether there are not publications in working days

    Args:
        data_df(DataFrame): Published table.
        column(String): Date type column to search for missing working days.
        start_date(String, optional): bottom of range.
        end_date(String, optional): top of range.
        return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                       description of each row with status OK. If return_ok is False the dataframe will
                                       be empty.
        return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                          if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                          if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

    Returns:
        pandas.Dataframe: Table with two columns.


        If empty there are publications in all possible ranges.

    Examples:
        >>> assert_daily_reports(pandas.Dataframe, "Column_A", return_ok=True, return_type='DataFrame')
           searches for missing working days between Min(Column_A) and Max(Column_A)
           return: If no working days missing: DataFrame with Ok Status
                   If missing working days: DataFrame with Alert Status

        >>> assert_daily_reports(pandas.Dataframe, "Column_A", return_ok=False, return_type='DataFrame')
           searches for missing working days between Min(Column_A) and Max(Column_A)
           return: If no working days missing: Empty DataFrame
                   If missing working days: DataFrame with Alert Status

        >>> assert_daily_reports(pandas.Dataframe, "Column_A", return_type='Bool')
           searches for missing working days between Min(Column_A) and Max(Column_A)
           return: If no working days missing: True
                   If missing working days: False

        >>> assert_daily_reports(pandas.Dataframe, "Column_A", return_ok=False, return_type='Tuple')
           searches for missing working days between Min(Column_A) and Max(Column_A)
           return: If no working days missing: (True, Empty DataFrame)
                   If missing working days: (False, DataFrame with Alert Status)

        >>> assert_daily_reports(pandas.Dataframe, "Column_A", start_date="2020-12-30", end_date='2020-10-30')
           searches for missing working days between 2020-10-30 and 2020-12-30
           return: If no working days missing: DataFrame with Ok Status
                   If missing working days: DataFrame with Alert Status

        >>> from prefect import task
        >>> from DORC_Utils import BBM_Flow, read_publicador, assert_daily_reports
        >>>
        >>> with BBM_Flow("My flow") as flow:
        >>>     data_df = read_publicador(
        >>>         615, # PosicaoAtivos
        >>>         dataref_inicio='20200102',
        >>>         dataref_fim='20200102'
        >>>     )
        >>>     results = assert_daily_reports(
        >>>         data_df
        >>>     )
        >>>
        >>> if __name__ == "__main__":
        >>>     flow.run()

    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')

    column = column if column else 'Data Referência'
    if type(column) != str:
        raise TypeError(f"column should be a string not {type(column)}")
    if (type(start_date) != str and start_date is not None) or (type(end_date) != str and end_date is not None):
        raise TypeError(
            f"start_date and end_date should be a string or None not {type(start_date)} and {type(end_date)}")
    try:
        start_date = datetime.strptime(start_date, "%Y-%m-%d") if start_date else data_df[column].min()
        end_date = datetime.strptime(end_date, "%Y-%m-%d") if end_date else data_df[column].max()
    except:
        raise Exception("start_date and end_date should be in format YYYY-MM-DD")
    if start_date > end_date:
        raise Exception("start_date cannot be greater than end_date")
    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")

    if data_df[column].infer_objects().dtype == numpy.object:
        data_df[column] = pd.to_datetime(data_df[column])

    validations = pd.DataFrame(columns=['Status', 'Comments'])

    gaps = _find_gap_wd(data_df[column].to_list(), start_date, end_date)
    if gaps:
        validation = pd.DataFrame({'Status': ['Alert']})
        comments = get_comments(data_df, True)
        comments['Missing_working_days'] = [[x.strftime("%Y-%m-%d") for x in gaps]]
        comments['Column'] = column
        validation['Comments'] = comments.to_dict(orient='records')
        validations = validations.append(validation)

    return get_assert_return(data_df, validations, return_ok, return_type)


@task
def assert_data_consistency(data_df, columns, operators, return_ok=True, return_type='DataFrame'):
    """
        Assert data consistency between columns

        Args:
            data_df(DataFrame): Published table.
            columns(Tuple(String) or List(Tuple(String))): Tuple with 2 columns or list of tuples with two columns
            operators(String or List(String)): operator (<, <=, =, >=, >, !=) or list with operators
            return_ok(Bool, optional): default is True. If True and no Danger found, OK Status will be returned
            return_ok(bool, optional): if no problems were found and return_ok is True the response dataframe will have a
                                           description of each row with status OK. If return_ok is False the dataframe will
                                           be empty.
            return_type(string, optional): if return_type is "DataFrame" the function's return will be a DataFrame.
                                              if return_type is "Bool" the function's return will be a Boolean. True if no problem were found and False if it doesn't pass validation.
                                              if return_type is "Tuple" the function's return will be a Tuple of size 2. The first value being the Boolean and the second being a DataFrame.

        Returns:
            pandas.Dataframe: Table with two columns.


            If empty there are data consistency between columns.

        Examples:
            >>> assert_data_consistency(pandas.Dataframe, columns=('Column_A','Column_B'), operators="<", return_ok=True, return_type='DataFrame')
                assert if "Column_A" < "Column_B"
                return: If "Column_A" < "Column_B": DataFrame with Ok Status.
                        If "Column_A" >= "Column_B": DataFrame with Alert Status.

            >>> assert_data_consistency(pandas.Dataframe, columns=('Column_A','Column_B'), operators="<", return_ok=False, return_type='DataFrame')
                assert if "Column_A" < "Column_B"
                return: If "Column_A" < "Column_B": Empty DataFrame.
                        If "Column_A" >= "Column_B": DataFrame with Alert Status.

            >>> assert_data_consistency(pandas.Dataframe, columns=('Column_A','Column_B'), operators="<", return_type='Bool')
                assert if "Column_A" < "Column_B"
                return: If "Column_A" < "Column_B": True.
                        If "Column_A" >= "Column_B": False.

            >>> assert_data_consistency(pandas.Dataframe, columns=('Column_A','Column_B'), operators="<", return_ok=False, return_type='Bool')
                assert if "Column_A" < "Column_B"
                return: If "Column_A" < "Column_B": (True, Empty DataFrame).
                        If "Column_A" >= "Column_B": (False, DataFrame with Alert Status).

            >>> assert_data_consistency(pandas.Dataframe, columns=[('Column_A','Column_B'), ("Columns_A", "Column_C")], operators="<")
                assert if "Column_Ah" < "Column_B" and "Column_A" < "Column_C"
                return: If "Column_A" < "Column_B" and "Column_A" < "Column_C": DataFrame with Ok Status.
                        If "Column_A" >= "Column_B" or "Column_A" >= "Column_C": DataFrame with Alert Status.

            >>> from prefect import task
            >>> from DORC_Utils import BBM_Flow, read_publicador, assert_data_consistency
            >>>
            >>> with BBM_Flow("My flow") as flow:
            >>>     data_df = read_publicador(
            >>>         615, # PosicaoAtivos
            >>>         dataref_inicio='20200102',
            >>>         dataref_fim='20200102'
            >>>     )
            >>>     results = assert_data_consistency(
            >>>         data_df,
            >>>         ('Column_A','Column_B'),
            >>>         "<="
            >>>     )
            >>>
            >>> if __name__ == "__main__":
            >>>     flow.run()
    """
    return_type = return_type.lower()
    if return_type not in ('bool', 'dataframe', 'tuple'):
        raise ValueError(f'return_type must be one of the following [bool|dataframe|tuple] and not {return_type}')
    if (type(columns) != list and type(columns) != tuple) or (type(columns) == list and type(columns[0]) != tuple):
        raise TypeError(f"columns should be a tuple or tuple List not {type(columns)}")
    if (type(columns) == tuple and type(columns[0]) != str) or (type(columns) == list and type(columns[0][0]) != str):
        raise TypeError(f"value of columns should be a string not {type(columns[0][0])}")
    if (type(operators) != list and type(operators) != str) or (type(operators) == list and type(operators[0]) != str):
        raise TypeError(f"operators should be a String or String List not {type(columns)}")
    if not ('__report_id' in data_df.columns or '__publication_id' in data_df.columns):
        raise Exception("Expected parameter_columns = True on the corresponding read task")
    if type(columns) == tuple:
        columns = [columns]

    kwargs_dict = {
        'Columns': columns,
        'Operator': operators
    }
    kwargs_dict, lcm = normalize(kwargs_dict)
    validations = pd.DataFrame(columns=['Status', 'Comments'])
    for i in range(lcm):
        kwargs_i = {}
        for k, _ in kwargs_dict.items():
            kwargs_i[k] = kwargs_dict[k][i]

        if data_df[kwargs_i['Columns'][0]].infer_objects().dtype != data_df[kwargs_i['Columns'][0]].infer_objects().dtype:
            raise Exception(f"Operation {kwargs_i['Operation']} invalid for Column "
                            f"{data_df[kwargs_i['Columns'][0]]} of type"
                            f"{data_df[kwargs_i['Columns'][0]].infer_objects().dtype} and Column "
                            f"{data_df[kwargs_i['Columns'][0]]} of type "
                            f"{data_df[kwargs_i['Columns'][0]].infer_objects()}")

        if kwargs_i['Operator'] == '<=':
            bool_result = data_df[kwargs_i['Columns'][0]] <= data_df[kwargs_i['Columns'][1]]
        elif kwargs_i['Operator'] == '<':
            bool_result = data_df[kwargs_i['Columns'][0]] < data_df[kwargs_i['Columns'][1]]
        elif kwargs_i['Operator'] == '=':
            bool_result = data_df[kwargs_i['Columns'][0]] == data_df[kwargs_i['Columns'][1]]
        elif kwargs_i['Operator'] == '>':
            bool_result = data_df[kwargs_i['Columns'][0]] > data_df[kwargs_i['Columns'][1]]
        elif kwargs_i['Operator'] == '>=':
            bool_result = data_df[kwargs_i['Columns'][0]] >= data_df[kwargs_i['Columns'][1]]
        elif kwargs_i['Operator'] == '!=':
            bool_result = data_df[kwargs_i['Columns'][0]] != data_df[kwargs_i['Columns'][1]]
        else:
            raise Exception(f"Operator {kwargs_i['Operator']} is not valid")

        if not bool_result[bool_result == False].empty:
            data_df_aux = data_df.loc[list(bool_result[bool_result == False].index), :]
            data_df_aux['__Column_Values'] = data_df_aux.to_dict(orient='records')
            validation_i = pd.DataFrame({'Status': ['Alert']})
            comments = get_comments(data_df, True)
            comments['Column_A'] = kwargs_i['Columns'][0]
            comments['Column_B'] = kwargs_i['Columns'][1]
            comments['Operator'] = kwargs_i['Operator']
            validation_i['Comments'] = comments.to_dict(orient='records')
            validations = validations.append(validation_i, ignore_index=True)

    return get_assert_return(data_df, validations, return_ok, return_type)
